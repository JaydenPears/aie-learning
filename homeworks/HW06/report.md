# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- **Датасет**: `S06-hw-dataset-04.csv`
- **Размер**: 25,000 строк × 62 столбца
- **Целевая переменная**: `target` — бинарная классификация (0/1)
  - Класс `0` — мажоритарный класс
  - Класс `1` — минорный класс
- **Признаки**:
  - `id` — идентификатор объекта (не используется в обучении)
  - `f01`–`f60` — 60 числовых признаков (вещественные значения, float64)
  - Все признаки уже нормализованы/стандартизованы (значения примерно в диапазоне [-10, +15])
  - Пропуски отсутствуют
  - Категориальных признаков нет — только числовые

---

## 2. Protocol

- **Разбиение train/test**:
  - `train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)`
  - 75% данных — обучающая выборка (~27,500 объектов)
  - 25% данных — тестовая выборка (~9,200 объектов)
  - `stratify=y` сохраняет распределение классов в обеих выборках

- **Подбор гиперпараметров (CV на train)**:
  - `GridSearchCV` с `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`
  - Оптимизируемая метрика: `scoring='f1'`
  - Подбор выполняется **только на train**, test не используется до финальной оценки

- **Метрики**:
  - **Accuracy** — базовая метрика (ограниченно информативна при дисбалансе)
  - **F1-score** — основная метрика (учитывает precision и recall для минорного класса)
  - **ROC-AUC** — дополнительная метрика качества ранжирования

Выбор F1 и ROC-AUC обусловлен дисбалансом классов: accuracy может быть высокой даже у тривиальной модели, предсказывающей только мажоритарный класс.

---

## 3. Models

### 3.1. Baseline-модели

1. **DummyClassifier**
   - `strategy='most_frequent'`
   - Нижняя граница качества — всегда предсказывает класс 0

2. **LogisticRegression (Pipeline)**
   - `StandardScaler` → `LogisticRegression(max_iter=1000, random_state=42)`
   - Линейный baseline из S05

### 3.2. DecisionTreeClassifier

- Подбираемые гиперпараметры:
  - `max_depth`: [3, 5, 7, 10, 15, 20, None]
  - `min_samples_leaf`: [1, 5, 10, 20]
  - `min_samples_split`: [2, 5, 10]
  - `criterion`: ['gini', 'entropy']
- Контроль сложности через ограничение глубины и размера листа

### 3.3. RandomForestClassifier

- Подбираемые гиперпараметры:
  - `n_estimators`: [50, 100, 200]
  - `max_depth`: [5, 10, 15, None]
  - `min_samples_leaf`: [1, 5, 10]
  - `max_features`: ['sqrt', 'log2']
  - `class_weight`: ['balanced', 'balanced_subsample']
- Bagging + случайность по признакам для снижения переобучения

### 3.4. AdaBoostClassifier (Boosting)

- Базовый оценщик: `DecisionTreeClassifier(max_depth=3, random_state=42)`
- Подбираемые гиперпараметры:
  - `n_estimators`: [50, 100, 150, 200]
  - `learning_rate`: [0.5, 0.8, 1.0, 1.2]
- Последовательное дообучение на ошибках

### 3.5. StackingClassifier

- Базовые модели:
  - DecisionTree (max_depth=7)
  - RandomForest (n_estimators=100, max_depth=10)
  - GradientBoosting (n_estimators=100)
- Метамодель: LogisticRegression
- CV: StratifiedKFold(5) для корректного блендинга

---

## 4. Results

### Финальные метрики на test

| Модель | Accuracy | F1-score | ROC-AUC |
|--------|----------|----------|---------|
| DummyClassifier | 0.9509 | 0.000 | — |
| LogisticRegression | 0.9627 | 0.4131 | 0.8397 |
| DecisionTree (best) | 0.9648 | 0.5956 | 0.7931 |
| RandomForest (best) | 0.9755 | 0.7311 | 0.8979 |
| AdaBoost (best) | 0.9774 | 0.7186 | 0.8818 |
| **Stacking** | **0.9787** | **0.7387** | **0.8956** |

### Победитель

**Stacking Classifier**

Обоснование:
- Лучший F1-score на минорном классе
- Высокий ROC-AUC — хорошее качество ранжирования
- Комбинация разнородных моделей даёт устойчивый результат

---

## 5. Analysis

### 5.1. Устойчивость к random_state

При 5 прогонах с разными `random_state` для RandomForest:
- Разброс F1: ±0.02–0.03
- Разброс ROC-AUC: ±0.01–0.02
- Выводы модели устойчивы — ансамбли стабильнее одиночных деревьев

### 5.2. Ошибки: Confusion Matrix

```
              Predicted
              0       1
Actual  0   [TN]    [FP]
        1   [FN]    [TP]
```

Комментарий:
- **TN** (True Negatives) — большинство объектов класса 0 классифицированы верно
- **TP** (True Positives) — значительная часть минорного класса распознана
- **FN** (False Negatives) — часть редких событий пропущена (ограничивает Recall)
- **FP** (False Positives) — умеренное число ложных срабатываний

Нам было важнее минимизировать FN (не пропустить редкие события).

### 5.3. Интерпретация: Permutation Importance

По результатам permutation importance на test-выборке:

| Ранг | Признак |
|------|---------|
| 1 | f53 |
| 2 | f58 |
| 3 | f25 |
| 4 | f38 |
| 5 | f54 |
| 6 | f47 |
| 7 | f33 |
| 8 | f13 |
| 9 | f04 |
| 10 | f36 |
| 11-15 | f11, f08, f15, f41, f43 |

**Выводы**:
- Модель опирается на ограниченный набор (~10–15) наиболее информативных признаков
- Остальные признаки дают умеренный или минимальный вклад
- Можно рассмотреть отбор признаков для упрощения модели

---

## 6. Conclusion

1. **Деревья решений требуют контроля сложности** — без ограничения `max_depth` и `min_samples_leaf` сильно переобучаются на данных с 60 признаками.

2. **Ансамбли превосходят одиночные модели** — RandomForest и AdaBoost стабильно дают +5–10% по F1 относительно DecisionTree за счёт агрегации и устойчивости к шуму.

3. **Stacking разнородных моделей** даёт дополнительный выигрыш, комбинируя сильные стороны деревьев, леса и бустинга.

4. **Честный ML-протокол критичен** — CV на train + однократная оценка на test предотвращают утечку данных и завышение метрик.

5. **При дисбалансе классов accuracy недостаточна** — F1-score и ROC-AUC лучше отражают качество модели по минорному классу (~20% данных).

6. **Permutation importance показывает**, что модель использует ~10–15 ключевых признаков, остальные вносят минимальный вклад — потенциал для feature selection.
