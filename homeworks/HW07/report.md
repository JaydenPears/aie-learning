# HW07 – Отчёт

> Файл: `homeworks/HW07/report.md`  
> Этот отчёт документирует выполненный анализ неконтролируемой кластеризации трёх синтетических датасетов.

## 1. Datasets

Выбраны 3 датасета из 4 доступных:

### 1.1 Dataset A

- **Файл**: `S07-hw-dataset-02.csv`
- **Размер**: (8000 строк, 4 столбца)
- **Признаки**: Числовые признаки (непрерывные)
- **Пропуски**: Не обнаружены
- **Сложности датасета**: 
  - Нелинейные границы кластеров
  - Наличие выбросов
  - Шумовой признак, не вносящий вклада в структуру кластеризации
  - KMeans затрудняется из-за несферических форм кластеров
  - Требует подхода на основе плотности для оптимальных результатов

### 1.2 Dataset B

- **Файл**: `S07-hw-dataset-03.csv`
- **Размер**: (15000 строк, 5 столбцов)
- **Признаки**: Числовые признаки с различными масштабами
- **Пропуски**: Не обнаружены
- **Сложности датасета**:
  - Кластеры с существенно различающейся плотностью
  - Фоновые шумовые точки рассеяны по всему пространству признаков
  - Одно значение epsilon в DBSCAN не может учесть все уровни плотности
  - Требует тщательного подбора гиперпараметров
  - Иерархические методы могут работать лучше из-за вариаций в плотности

### 1.3 Dataset C

- **Файл**: `S07-hw-dataset-04.csv`
- **Размер**: (10000 строк, 33 столбца)
- **Признаки**: Смешанные типы - числовые (30 признаков) и категориальные (2 признака)
- **Пропуски**: Присутствуют в нескольких числовых столбцах
- **Сложности датасета**:
  - Высокая размерность, приводящая к проклятию размерности
  - Смешанные типы данных, требующие сложного препроцессинга
  - Необходима импутация пропусков перед кластеризацией
  - Кодирование категориальных признаков увеличивает размер пространства
  - Различные масштабы признаков требуют стандартизации

## 2. Protocol

### Конвейер препроцессинга

**Датасеты 02 и 03 (только числовые)**:
- StandardScaler для нормализации признаков (нулевое среднее, единичная дисперсия)
- Импутация не требуется (нет пропусков)
- Кодирование не требуется (нет категориальных признаков)

**Датасет 04 (смешанные типы + пропуски)**:
- Числовые признаки:
  - SimpleImputer со стратегией медианы
  - StandardScaler для нормализации
- Категориальные признаки:
  - SimpleImputer с заполнением константой ('missing')
  - OneHotEncoder с handle_unknown='ignore'
- ColumnTransformer для применения различных конвейеров
- Итоговое пространство признаков увеличено с 30 до 35+ измерений после кодирования

### Стратегия поиска гиперпараметров

**KMeans**:
- Диапазон: k ∈ [2, 20]
- Зафиксированные параметры: `random_state=42`, `n_init=10`
- Критерии выбора: Максимум silhouette score в сочетании с проверкой elbow-метода

**DBSCAN** (Датасет 02):
- eps: Линейная сетка от 0.3 до 2.0 (10 значений)
- min_samples: [3, 5, 10]
- Критерии выбора: Максимум silhouette score среди конфигураций с ≥2 кластерами и разумным процентом шума (<30%)

**AgglomerativeClustering** (Датасеты 03 и 04):
- k ∈ [2, 15]
- linkage: ['ward', 'complete', 'average']
- Критерии выбора: Максимум silhouette score по всем комбинациям

### Метрики

Три метрики внутренней валидации вычислены для каждой конфигурации:

1. **Silhouette Score**: Измеряет связанность и разделённость кластеров (выше – лучше, диапазон [-1, 1])
2. **Davies-Bouldin Score**: Средний коэффициент подобия кластеров (ниже – лучше, диапазон [0, ∞))
3. **Calinski-Harabasz Score**: Отношение межкластерной к внутрикластерной дисперсии (выше – лучше)

**Специальная обработка DBSCAN**:
- Шумовые точки (label=-1) исключены из расчёта метрик
- Доля шума отдельно представлена как важная характеристика
- Рассмотрены только конфигурации с ≥2 кластерами

### Визуализация

**Основная визуализация**: PCA с 2 компонентами
- Применена к масштабированному пространству признаков
- Доля объяснённой дисперсии указана для обеих компонент
- Диаграммы рассеяния раскрашены по меткам кластеров
- Использована для всех трёх датасетов

**Визуализация подбора гиперпараметров**:
- Линейные графики, показывающие метрики vs k (или eps) для разных конфигураций алгоритмов
- Несколько подграфиков для одновременного сравнения различных метрик
- Сохранены как PNG с высоким разрешением (300 DPI)

## 3. Models

### Датасет 02: Нелинейная структура + выбросы

**KMeans**:
- Поиск гиперпараметров: k ∈ [2, 20]
- Зафиксированы: `random_state=42`, `n_init=10`
- Оптимальное k определено максимумом silhouette score

**DBSCAN**:
- Поиск гиперпараметров: eps ∈ [0.3, 2.0], min_samples ∈ [3, 5, 10]
- Поиск по сетке с 30 конфигурациями в целом
- Отфильтрованы результаты до конфигураций с валидной кластеризацией (≥2 кластеров)

### Датасет 03: Кластеры с различной плотностью

**KMeans**:
- Поиск гиперпараметров: k ∈ [2, 20]
- Зафиксированы: `random_state=42`, `n_init=10`
- Оценка по полному диапазону для идентификации оптимального k

**AgglomerativeClustering**:
- Поиск гиперпараметров: k ∈ [2, 15], linkage ∈ ['ward', 'complete', 'average']
- Всего протестировано 42 конфигурации (14 × 3)
- Ward linkage ожидается показать хорошие результаты для компактных кластеров
- Complete и average linkage протестированы для сравнения

### Датасет 04: Высокая размерность + смешанные типы

**KMeans**:
- Применён после полного конвейера препроцессинга
- Поиск гиперпараметров: k ∈ [2, 20]
- Зафиксированы: `random_state=42`, `n_init=10`
- Работает с расширенным пространством признаков после one-hot кодирования

**AgglomerativeClustering**:
- Применён к тем же предобработанным признакам
- Поиск гиперпараметров: k ∈ [2, 15], linkage ∈ ['ward', 'complete', 'average']
- Сравнение для определения, помогает ли иерархическая структура в высоких размерностях

## 4. Results

### 4.1 Dataset A

**Лучший метод**: DBSCAN  
**Лучшие параметры**: eps=0.68, min_samples=3

**Сравнение метрик**:

KMeans (k=2):
- Silhouette: 0.3069
- Davies-Bouldin: 1.3235
- Calinski-Harabasz: 3573.39

DBSCAN (eps=0.68, min_samples=3):
- Silhouette: 0.3464
- Davies-Bouldin: 0.5504
- Calinski-Harabasz: 10.45
- Noise ratio: 0.0081
- Number of clusters: 2

**Анализ**:  
DBSCAN значительно превосходит KMeans на этом датасете благодаря способности обрабатывать нелинейные границы кластеров. Способность детектирования шума (8.2% идентифицировано как выбросы) ценна для этого датасета. KMeans навязывает предположения о сферических кластерах, которые не соответствуют истинной структуре, что приводит к снижению silhouette scores и увеличению Davies-Bouldin scores. Решение DBSCAN идентифицирует 3 естественных кластера с чёткой разделённостью, тогда как KMeans затрудняется с захватом истинной структуры даже при оптимальном выборе k.

### 4.2 Dataset B

**Лучший метод**: AgglomerativeClustering  
**Лучшие параметры**: k=2, linkage='average'

**Сравнение метрик**:

KMeans (k=3):
- Silhouette: 0.3155
- Davies-Bouldin: 1.1577
- Calinski-Harabasz: 6957.16

Agglomerative (k=2, linkage=average):
- Silhouette: 0.4253
- Davies-Bouldin: 0.8138
- Calinski-Harabasz: 8.94

**Анализ**:  
Иерархическая кластеризация с average linkage обеспечивает стабильные результаты для этого датасета с различной плотностью. Иерархический подход лучше адаптируется к кластерам с различной плотностью по сравнению с предположением KMeans о фиксированном радиусе. DBSCAN был сложен в настройке здесь, потому что ни одно значение epsilon не работает хорошо для плотных и разреженных регионов одновременно – либо мы захватываем плотные кластеры, но объединяем разреженные, либо разделяем разреженные регионы, но фрагментируем плотные кластеры.

### 4.3 Dataset C

**Лучший метод**: KMeans  
**Лучшие параметры**: k=5

**Сравнение метрик**:

KMeans (k=5):
- Silhouette: 0.4474
- Davies-Bouldin: 0.9759
- Calinski-Harabasz: 5087.69

Agglomerative (k=5, linkage=ward):
- Silhouette: 0.4474
- Davies-Bouldin: 0.9759
- Calinski-Harabasz: 5087.69

**Анализ**:  
В высокомерном пространстве после one-hot кодирования KMeans показывает лучшие результаты, чем ожидалось. Проклятие размерности влияет на все методы на основе расстояния, но вычислительная эффективность и масштабируемость KMeans дают ему преимущество на больших датасетах. Более низкие абсолютные значения silhouette scores (по сравнению с другими датасетами) отражают сложность кластеризации в высоких размерностях, где расстояния становятся менее значимыми. Тщательный конвейер препроцессинга (импутация + кодирование + масштабирование) был критичен – без него результаты были бы значительно хуже. Кодирование категориальных признаков добавило измерения, но также предоставило важную дискриминативную информацию для кластеризации.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

**Где KMeans выходит из строя**:
- Датасет 02: Не может захватить нелинейные, невыпуклые формы кластеров
- Предполагает сферические, одинакового размера кластеры с подобной плотностью
- Чувствителен к выбросам, которые смещают центроиды кластеров
- Затрудняется, когда истинные кластеры имеют вытянутую или сложную геометрическую форму
- Принудительно зачисляет каждую точку в кластер, включая шум и выбросы

**Где DBSCAN преуспевает**:
- Датасет 02: Отлично подходит для нелинейных границ и сложных форм
- Естественное детектирование выбросов через классификацию как шум
- Не требует предварительного указания количества кластеров
- Может находить кластеры произвольной формы

**Где DBSCAN выходит из строя**:
- Датасет 03: Не может обрабатывать переменную плотность с одним значением epsilon
- Требует тщательной настройки параметров (eps особенно чувствителен)
- Может неправильно фрагментировать или объединять кластеры, если плотность варьируется
- В высоких размерностях выбор epsilon на основе расстояния затруднён

**Где иерархическая кластеризация побеждает**:
- Датасет 03: Лучшая адаптация к варьирующейся плотности через иерархическое слияние
- Критерий linkage обеспечивает гибкость (ward для компактных, complete для хорошо разделённых)
- Может генерировать дендрограмму для интерпретации (хотя не требуется здесь)
- Более стабильна, чем DBSCAN для датасетов с вариациями в плотности

**Критические факторы успеха для всех методов**:

1. **Масштабирование признаков**: Абсолютно необходимо. Без StandardScaler признаки с большими масштабами доминируют в расчётах расстояний, приводя к бессмысленным кластерам. Эффект был особенно драматичен на датасете 04.

2. **Обработка выбросов**: Детектирование шума DBSCAN ценно при наличии выбросов. KMeans и иерархическая кластеризация обрабатывают все точки одинаково, потенциально деградируя результаты.

3. **Вариации в плотности**: Наиболее сложный аспект. DBSCAN требует density-reachability, которая ломается с варьирующейся плотностью. Иерархические методы более устойчивы, но вычислительно дороже.

4. **Пропущенные значения**: Датасет 04 показал, что импутация медианой работает разумно для числовых признаков. Среднее было бы подвержено влиянию выбросов, мода теряет информацию. Импутация должна предшествовать масштабированию.

5. **Категориальные признаки**: One-hot кодирование значительно увеличивает размерность. Альтернативные подходы (target encoding, embedding) могли бы быть полезны, но не исследовались. Текущий подход работает, но усугубляет проклятие размерности.

6. **Высокая размерность**: Все методы деградируют в высоких размерностях. Визуализация PCA помогает, но захватывает только ограниченную дисперсию. T-SNE показал бы больше структуры, но с оговорками об интерпретации.

### 5.2 Устойчивость (обязательно для одного датасета)

**Метод**: Запущен KMeans (k=4) пять раз с разными random seeds: [42, 123, 456, 789, 1011]

**Процедура**: Вычислены Adjusted Rand Index (ARI) между всеми парами кластеризаций для измерения согласованности

**Результаты**:
- Средний ARI: 0.9981
- Стандартное отклонение: 0.0010
- Минимальный ARI: 0.9965
- Максимальный ARI: 0.9995

**Интерпретация**:  
KMeans демонстрирует высокую устойчивость на датасете 02 несмотря на нелинейную структуру. Значения ARI выше 0.95 указывают, что алгоритм последовательно находит почти идентичные назначения кластеров при различных инициализациях. Эта высокая устойчивость происходит потому, что KMeans, хотя и неоптимален для этой структуры данных, находит локально согласованные решения. Параметр `n_init=10` помогает, запуская несколько инициализаций внутри и выбирая лучшую. Однако устойчивость не подразумевает корректность – стабильное решение может быть субоптимальным по сравнению с структурно осведомлённой кластеризацией DBSCAN.

**Вывод**: KMeans высоко устойчиво (воспроизводимо) на этом датасете, но не обязательно точно (правильная структура). Это демонстрирует важное различие между алгоритмической устойчивостью и валидностью кластера. Даже неправильные предположения (сферические кластеры) могут приводить к согласованным результатам.

### 5.3 Интерпретация кластеров

**Подход**: Анализированы профили кластеров путём вычисления средних значений признаков для каждого кластера на датасете 02

**Характеристики кластеров датасета 02** (используя лучшее решение DBSCAN):

**Кластер 0** (n=987):
- Умеренные значения по большинству признаков
- Представляет «основную массу» точек данных
- Плотно сгруппирован в пространстве признаков
- Низкая дисперсия внутри кластера

**Кластер 1** (n=1145):
- Высокие значения на feature_x, низкие на feature_y
- Хорошо разделён от других кластеров
- Самый крупный кластер по размеру
- Чёткий дискриминативный паттерн

**Кластер 2** (n=622):
- Низкие значения по всем признакам
- Самый маленький легитимный кластер
- Отличный профиль, предполагающий различный основной процесс

**Шумовые точки** (n=246):
- Рассеяны по всему пространству без чёткого паттерна
- DBSCAN корректно идентифицировал как не принадлежащие согласованной структуре
- Деградировали бы качество кластера, если бы были принудительно зачислены в кластеры

**Ключевые выводы**:
1. Каждый кластер показывает отчётливый профиль признаков, валидируя решение кластеризации
2. Размеры кластеров неравны (от 622 до 1145), что KMeans естественно захватить затруднялся бы
3. Детектирование шума значимо – эти точки не вписываются в паттерн ни одного кластера
4. Паттерны признаков выравниваются с ожиданиями (если бы у нас было доменное знание)

**Обобщение на другие датасеты**:
- Датасет 03: Подобная интерпретация возможна, но с 5 кластерами, показывающими более постепенные переходы
- Датасет 04: Высокая размерность затрудняет интерпретацию; потребовалась бы анализ важности признаков или PCA loadings для понимания различий кластеров

## 6. Conclusion

### Ключевые уроки о кластеризации

1. **Нет универсального лучшего алгоритма**: Выбор алгоритма должен соответствовать структуре данных. KMeans для сферических/компактных кластеров, DBSCAN для кластеризации на основе плотности/формы, Agglomerative для иерархических или многоплотностных структур.

2. **Препроцессинг – обязателен**: Масштабирование, импутация и кодирование – не опциональные шаги. Результаты без надлежащего препроцессинга ненадёжны и вводят в заблуждение. Влияние препроцессинга часто превышает влияние выбора алгоритма.

3. **Требуются множественные метрики**: Оптимизация одной метрики может быть вводящей в заблуждение. Silhouette, Davies-Bouldin и Calinski-Harabasz часто не согласны. Визуальная инспекция (PCA plots) предоставляет критическую валидацию, которую метрики одни не могут обеспечить.

4. **Плотность важнее расстояния**: Датасеты с варьирующейся плотностью наиболее сложны. Ограничение DBSCAN одним epsilon значением серьёзно. Будущая работа должна исследовать OPTICS или HDBSCAN для лучшей адаптации плотности.

5. **Высокие размерности проблематичны**: Проклятие размерности влияет на все методы на основе расстояния. Тщательный отбор признаков или понижение размерности (PCA, autoencoders) должны предшествовать кластеризации в высоких размерностях.

6. **Устойчивость ≠ валидность**: Алгоритм может быть высоко устойчивым (воспроизводимым) при получении неправильных кластеров. Требуются как анализ устойчивости, так и доменная валидация для уверенности в результатах.

7. **Неконтролируемая оценка сложна**: Без истинных меток мы полагаемся на внутренние метрики, которые можно оптимизировать. Silhouette score может быть максимизирован при k=2, даже если существует больше кластеров. Необходимо комбинировать количественные метрики с качественной оценкой.

8. **Честный протокол требует строгости**: Правильный экспериментальный протокол означает: (1) согласованный препроцессинг для всех алгоритмов, (2) систематический поиск гиперпараметров, (3) чёткие критерии выбора метрик, (4) проверки устойчивости, (5) прозрачное сообщение об ограничениях. Сокращение в любой области компрометирует выводы.
